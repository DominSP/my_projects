{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5454545454545454\n",
      "Precision: 0.6\n",
      "Recall: 0.5\n",
      "F1 Score: 0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ocena klasyfikacji binarnej\n",
    "def classification_metrics(correct, predicted):\n",
    "    tp = np.sum((correct == 1) & (predicted == 1)) # TruePositive\n",
    "    tn = np.sum((correct == 0) & (predicted == 0)) # TrueNegative\n",
    "    fp = np.sum((correct == 0) & (predicted == 1)) # FalsePositive (błąd typu I)\n",
    "    fn = np.sum((correct == 1) & (predicted == 0)) # FalseNegative (błąd typu II)\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Przykladowe dane\n",
    "correct = np.array([0,1,0,1,1,1,0,0,1,1,0])\n",
    "predicted = np.array([1,1,0,0,1,1,1,0,0,0,0])\n",
    "\n",
    "accuracy, precision, recall, f1 = classification_metrics(correct, predicted)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, num_features, epochs = 500, learning_rate=0.01, epsilon=1e-10):\n",
    "        self.weights = np.random.rand(num_features)\n",
    "        self.bias = np.random.rand(1)[0]\n",
    "        self.epochs = epochs\n",
    "        self.epsilon = epsilon\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def predict(self, x): # funkcja aktywacji\n",
    "        return np.where(np.dot(x, self.weights) + self.bias >= 0, 1, 0)\n",
    "    \n",
    "    def train(self, x_train, y_train):\n",
    "            for _ in range(self.epochs):\n",
    "                prev_weights = self.weights.copy()\n",
    "\n",
    "                for x, y in zip(x_train, y_train):\n",
    "                    prediction = self.predict(x)\n",
    "                    update = y - prediction  # -1, 0, lub 1; jeśli 0 to wagi się nie aktualizują, ponieważ była poprawna predykcja\n",
    "                    \n",
    "                    self.weights += self.learning_rate * update * x\n",
    "                    self.bias += self.learning_rate * update\n",
    "\n",
    "                # Sprawdzenie, czy wagi się stabilizują\n",
    "                if np.linalg.norm(self.weights - prev_weights) < self.epsilon:\n",
    "                    break\n",
    " \n",
    "    def test(self, X):\n",
    "        return np.where( X @ self.weights + self.bias >= 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.73094725  7.18528284 64.41038317 24.66428237]\n",
      " [83.44155279 63.01982687 75.83614336 67.61127283]\n",
      " [99.39100517  9.61315971 14.93347999 72.15498409]\n",
      " ...\n",
      " [87.97905359 25.80428991 22.24284486 88.04449276]\n",
      " [80.20238287 21.64052602 41.48732363  3.6147353 ]\n",
      " [ 0.62492591 99.65803104 81.97150773 77.52295713]]\n",
      "[0 1 1 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "import csv    \n",
    "def open_csv(file_path):\n",
    "    x, y = [], []\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        csvreader = csv.reader(csvfile, delimiter=' ')\n",
    "        for row in csvreader:\n",
    "            x.append(list(map(float, row[:-1])))\n",
    "            y.append(int(row[-1]))\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x, y = open_csv('dataset.csv')       \n",
    "print(x)\n",
    "print(y)\n",
    "x_train = x[:7000]\n",
    "y_train = y[:7000]\n",
    "\n",
    "x_test = x[7000:]\n",
    "y_test = y[7000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True ...  True False  True]\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(4)\n",
    "perceptron.train(x_train, y_train)\n",
    "\n",
    "predicted = perceptron.test(x_test)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8146666666666667\n",
      "Precision: 0.6992969172525689\n",
      "Recall: 1.0\n",
      "F1 Score: 0.8230426479949077\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1 = classification_metrics(y_test, np.where(predicted,1, 0))\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
